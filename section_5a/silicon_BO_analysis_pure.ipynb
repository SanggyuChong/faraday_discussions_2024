{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32181cf-3c52-4d8a-9edd-31b6ac6d3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ase.io import read\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a96011-18b0-4f3f-93ca-bea2fc132881",
   "metadata": {},
   "source": [
    "### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ebaa44-b913-42a7-8d1f-ba0b23718a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(X_struc, E_struc, alpha):\n",
    "\n",
    "    ## get Cov matrix\n",
    "    XX = X_struc.T @ X_struc\n",
    "\n",
    "    ## add diagonal regularization matrix of the smoothness prior multiplied by alpha,\n",
    "    ## then also with body-order dependent beta*exp(nu)\n",
    "    reg_mat = np.eye(XX.shape[0]) * alpha\n",
    "    Xprime = XX + reg_mat\n",
    "    Xinv = np.linalg.inv(Xprime)\n",
    "\n",
    "    E_mean = E_struc.mean()\n",
    "    Y = X_struc.T @ (E_struc - E_mean)\n",
    "    \n",
    "    weights = Xinv @ Y\n",
    "        \n",
    "    return weights, E_mean\n",
    "\n",
    "\n",
    "def predict_compwise(X_struc, weights, E_mean, comp_dims):\n",
    "\n",
    "    raw_E = X_struc @ weights\n",
    "    tot_pred = raw_E + E_mean\n",
    "    \n",
    "    cw_preds = np.zeros((len(comp_dims), len(X_struc)))\n",
    "    comp_idxs = np.cumsum(np.array([0] + comp_dims))\n",
    "\n",
    "    for ci in range(len(comp_dims)):\n",
    "        cur_mask = np.zeros(np.array(comp_dims).sum())\n",
    "        cur_mask[comp_idxs[ci]:comp_idxs[ci+1]] += np.ones(comp_dims[ci])\n",
    "        masked_weights = weights * cur_mask\n",
    "        cw_preds[ci] = X_struc @ masked_weights + E_mean\n",
    "\n",
    "    return tot_pred, cw_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538562cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CPR(\n",
    "    train_struc_feats,\n",
    "    test_struc_feats,\n",
    "    alpha,\n",
    "    comp_dims,\n",
    "):\n",
    "    \n",
    "    X_struc_train = train_struc_feats\n",
    "    X_struc_test = test_struc_feats\n",
    "        \n",
    "    XX = X_struc_train.T @ X_struc_train\n",
    "    reg_mat = (np.eye(XX.shape[0])) * alpha\n",
    "    Xprime = XX + reg_mat\n",
    "\n",
    "    Xinv = np.linalg.inv(Xprime)\n",
    "\n",
    "    CPR = np.zeros((len(comp_dims), len(X_struc_test)))\n",
    "\n",
    "    comp_idxs = np.cumsum(np.array([0] + comp_dims))\n",
    "    \n",
    "    for ci in range(len(comp_dims)):\n",
    "        cur_mask = np.zeros(np.array(comp_dims).sum())\n",
    "        cur_mask[comp_idxs[ci]:comp_idxs[ci+1]] += np.ones(comp_dims[ci])\n",
    "        X_struc_test_cur = X_struc_test * cur_mask\n",
    "        CPR[ci] = 1 / np.einsum(\"ij, jk, ik -> i\", X_struc_test_cur, Xinv, X_struc_test_cur)\n",
    "    \n",
    "    return CPR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c8a357-2dae-4da9-a731-15219bda7599",
   "metadata": {},
   "source": [
    "### load clusters and ACE feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6400a308-20b5-4bd4-8656-e48558b08593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mer2 = read('datasets/Si2.xyz', ':')\n",
    "mer3 = read('datasets/Si3.xyz', ':')\n",
    "mer4 = read('datasets/Si4.xyz', ':')\n",
    "mer5 = read('datasets/Si5.xyz', ':')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c3fc87-9dbd-4b47-9f22-db00a33361bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## read feature vectors and smoothness prior from Julia\n",
    "path = \"./Si_ACE_featvecs/pure/\"\n",
    "\n",
    "X2 = [np.vstack([np.loadtxt(path + \"2mer/{}.txt\".format(i))]) for i in range(len(mer2))]\n",
    "X3 = [np.vstack([np.loadtxt(path + \"3mer/{}.txt\".format(i))]) for i in range(len(mer3))]\n",
    "X4 = [np.vstack([np.loadtxt(path + \"4mer/{}.txt\".format(i))]) for i in range(len(mer4))]\n",
    "X5 = [np.vstack([np.loadtxt(path + \"5mer/{}.txt\".format(i))]) for i in range(len(mer5))]\n",
    "\n",
    "## shuffle amoliq ids \n",
    "np.random.seed(1215)\n",
    "\n",
    "ids = np.array([i for i in range(len(mer2))])\n",
    "np.random.shuffle(ids)\n",
    "X2 = [X2[ii] for ii in ids]\n",
    "mer2 = [mer2[ii] for ii in ids]\n",
    "\n",
    "ids = np.array([i for i in range(len(mer3))])\n",
    "np.random.shuffle(ids)\n",
    "X3 = [X3[ii] for ii in ids]\n",
    "mer3 = [mer3[ii] for ii in ids]\n",
    "\n",
    "ids = np.array([i for i in range(len(mer4))])\n",
    "np.random.shuffle(ids)\n",
    "X4 = [X4[ii] for ii in ids]\n",
    "mer4 = [mer4[ii] for ii in ids]\n",
    "\n",
    "ids = np.array([i for i in range(len(mer5))])\n",
    "np.random.shuffle(ids)\n",
    "X5 = [X5[ii] for ii in ids]\n",
    "mer5 = [mer5[ii] for ii in ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b4dfe5-a45a-4dcd-ab17-5f8af345600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comp_dims = [48, 273, 505, 127]\n",
    "comp_idxs = np.cumsum(np.array([0] + comp_dims))\n",
    "nu = np.array([1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b8e8ee-c75c-4661-ae9f-c94d81697853",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subtract isolated atom energy\n",
    "isoE = -7881.32677981122\n",
    "\n",
    "E2 = [f.info['free_energy']/len(f) - isoE for f in mer2]\n",
    "E2 = np.array(E2)\n",
    "\n",
    "E3 = [f.info['free_energy']/len(f) - isoE for f in mer3]\n",
    "E3 = np.array(E3)\n",
    "\n",
    "E4 = [f.info['free_energy']/len(f) - isoE for f in mer4]\n",
    "E4 = np.array(E4)\n",
    "\n",
    "E5 = [f.info['free_energy']/len(f) - isoE for f in mer5]\n",
    "E5 = np.array(E5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4819ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer = read('datasets/Si2.xyz', ':')\n",
    "X_dimer = [np.vstack([np.loadtxt(path + \"2mer/{}.txt\".format(i))]).mean(axis=0) for i in range(len(dimer))]\n",
    "E_dimer = [f.info['free_energy']/len(f) - isoE for f in dimer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9729a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [f.get_all_distances(mic=True).max() for f in dimer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d84da",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48121dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 500\n",
    "add = 50\n",
    "\n",
    "X_vnl = np.vstack([feats.mean(axis=0) for feats in X5])\n",
    "E_vnl = E5\n",
    "\n",
    "X_2b = np.vstack([feats.mean(axis=0) for feats in X5[:train - add]] + \\\n",
    "                 [feats.mean(axis=0) for feats in X2[:add]]) \n",
    "E_2b = np.hstack([E5[:train - add], E2[:add]])\n",
    "                  \n",
    "X_3b = np.vstack([feats.mean(axis=0) for feats in X5[:train - 2*add]] + \\\n",
    "                 [feats.mean(axis=0) for feats in X2[:add]] + \\\n",
    "                 [feats.mean(axis=0) for feats in X3[:add]]) \n",
    "E_3b = np.hstack([E5[:train - 2*add], E2[:add], E3[:add]])\n",
    "\n",
    "X_4b = np.vstack([feats.mean(axis=0) for feats in X5[:train - 3*add]] + \\\n",
    "                 [feats.mean(axis=0) for feats in X2[:add]] + \\\n",
    "                 [feats.mean(axis=0) for feats in X3[:add]] + \\\n",
    "                 [feats.mean(axis=0) for feats in X4[:add]]) \n",
    "E_4b = np.hstack([E5[:train - 3*add], E2[:add], E3[:add], E4[:add]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1c8c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-3\n",
    "\n",
    "w_vnl, E_mean_vnl = train_model(X_vnl, E_vnl, alpha)\n",
    "w_2b, E_mean_2b = train_model(X_2b, E_2b, alpha)\n",
    "w_3b, E_mean_3b = train_model(X_3b, E_3b, alpha)\n",
    "w_4b, E_mean_4b = train_model(X_4b, E_4b, alpha)\n",
    "\n",
    "E5pred_vnl, _ = predict_compwise(X_vnl, w_vnl, E_mean_vnl, comp_dims)\n",
    "E5pred_2b, _ = predict_compwise(X_vnl, w_2b, E_mean_2b, comp_dims)\n",
    "E5pred_3b, _ = predict_compwise(X_vnl, w_3b, E_mean_3b, comp_dims)\n",
    "E5pred_4b, _ = predict_compwise(X_vnl, w_4b, E_mean_4b, comp_dims)\n",
    "\n",
    "E2pred_vnl, E2_cw_vnl = predict_compwise(X_dimer, w_vnl, E_mean_vnl, comp_dims)\n",
    "E2pred_2b, E2_cw_2b = predict_compwise(X_dimer, w_2b, E_mean_2b, comp_dims)\n",
    "E2pred_3b, E2_cw_3b = predict_compwise(X_dimer, w_3b, E_mean_3b, comp_dims)\n",
    "E2pred_4b, E2_cw_4b = predict_compwise(X_dimer, w_4b, E_mean_4b, comp_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db67feb-43e4-406c-bacc-a3c5a18b9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPR_vnl = calculate_CPR(X_vnl, X_vnl, alpha, comp_dims)\n",
    "CPR_2b = calculate_CPR(X_2b, X_vnl, alpha, comp_dims)\n",
    "CPR_3b = calculate_CPR(X_3b, X_vnl, alpha, comp_dims)\n",
    "CPR_4b = calculate_CPR(X_4b, X_vnl, alpha, comp_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9df8f1f-f73b-4095-bd80-b900f899ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"pure_results.npz\",\n",
    "         CPR_vnl = CPR_vnl.mean(axis=1),\n",
    "         CPR_2b = CPR_2b.mean(axis=1),\n",
    "         CPR_3b = CPR_3b.mean(axis=1),\n",
    "         CPR_4b = CPR_4b.mean(axis=1),\n",
    "         dists = np.array(dists),\n",
    "         E2pred_vnl=E2pred_vnl,\n",
    "         E2pred_2b=E2pred_2b,\n",
    "         E2pred_3b=E2pred_3b,\n",
    "         E2pred_4b=E2pred_4b,\n",
    "         E2_cw_vnl=E2_cw_vnl,\n",
    "         E2_cw_2b=E2_cw_2b,\n",
    "         E2_cw_3b=E2_cw_3b,\n",
    "         E2_cw_4b=E2_cw_4b,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb8a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
