{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR-guided dataset construction demo -- comparative analysis with low density bulk carbon\n",
    "\n",
    "This notebook is one of three that were created to conduct the analysis presented in Section 4 of [Chong et al.](https://pubs.rsc.org/en/content/articlelanding/2024/fd/d4fd00101j), \"Prediction rigidities for data-driven chemistry\".\n",
    "\n",
    "Analysis is devised such that we study the selection of structures that can best reduce the error for surface-containing carbon structures.\n",
    "\n",
    "Three approaches were considered:\n",
    "\n",
    "1) random selection of bulk carbon structures\n",
    "\n",
    "2) random selection of low-density carbon structures (this notebook)\n",
    "\n",
    "3) selecting the structure that improves the PR the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LE_ACE import LE_ACE\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "import ase.io\n",
    "import numpy as np\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define ACE parameters and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_ace = LE_ACE(\n",
    "    r_cut_rs=4.5,\n",
    "    r_cut=4.5,\n",
    "    E_max=[0.0, 1000.0, 300.0, 200.0, 100.0],\n",
    "    all_species=[6],\n",
    "    le_type=\"physical\",\n",
    "    factor=1.5,\n",
    "    factor2=-1.0,\n",
    "    cost_trade_off=False,\n",
    "    fixed_stoichiometry=False,\n",
    "    is_trace=False,\n",
    "    n_trace=-1,\n",
    "    device=device\n",
    ")\n",
    "n_feat = sum(tensor.shape[0] for tensor in le_ace.extended_LE_energies)\n",
    "\n",
    "def get_batches(list: list, batch_size: int) -> list:\n",
    "    batches = []\n",
    "    n_full_batches = len(list)//batch_size\n",
    "    for i_batch in range(n_full_batches):\n",
    "        batches.append(list[i_batch*batch_size:(i_batch+1)*batch_size])\n",
    "    if len(list) % batch_size != 0:\n",
    "        batches.append(list[n_full_batches*batch_size:])\n",
    "    return batches\n",
    "\n",
    "def add_features_to_covariance(calculator, batch, covariance):\n",
    "    features = calculator.compute_features(batch)\n",
    "    covariance += features.T @ features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = ase.io.read(\"C_highdens.xyz\", \":\")\n",
    "test_set = ase.io.read(\"C_surfamo.xyz\", \":\")\n",
    "candidate_set = ase.io.read(\"C_alldens.xyz\", \":\")\n",
    "lowdens_set =  ase.io.read(\"C_lowdens.xyz\", \":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in training_set:\n",
    "    f.info['energy'] /= len(f)\n",
    "for f in test_set:\n",
    "    f.info['energy'] /= len(f)\n",
    "for f in candidate_set:\n",
    "    f.info['energy'] /= len(f)                \n",
    "for f in lowdens_set:\n",
    "    f.info['energy'] /= len(f)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform baseline fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orig_covariance = torch.zeros(n_feat, n_feat, device=device)\n",
    "for batch in get_batches(training_set, batch_size):\n",
    "    add_features_to_covariance(le_ace, batch, orig_covariance)\n",
    "orig_covariance = orig_covariance + 1e-5 * torch.eye(orig_covariance.shape[0], device=orig_covariance.device, dtype=orig_covariance.dtype)\n",
    "inv_covariance = torch.linalg.inv(orig_covariance)\n",
    "target_features = le_ace.compute_features(test_set)\n",
    "features = torch.concatenate([le_ace.compute_features(batch) for batch in get_batches(candidate_set, batch_size)])\n",
    "cur_PR = 1 / torch.einsum(\"ij, jk, ik -> i\", target_features, inv_covariance, target_features)\n",
    "\n",
    "print(f\"INITIAL PR: {cur_PR.detach().cpu().numpy().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary fit (baseline):\n",
    "accuracy_dict = le_ace.train(\n",
    "    train_structures=training_set,\n",
    "    validation_structures=training_set,\n",
    "    test_structures=test_set,\n",
    "    do_gradients=False,\n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "print(accuracy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select additional structures and compute changes in the PR & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_structures_to_add = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chosen_strucs = []\n",
    "all_RMSEs = []\n",
    "all_PRs = []\n",
    "\n",
    "for ii in range(n_structures_to_add):\n",
    "\n",
    "    cur_PRs = []\n",
    "    cur_RMSEs = []\n",
    "\n",
    "    ## repeating 10 times for statistics over random selection\n",
    "    for j in range(10):\n",
    "\n",
    "        np.random.shuffle(lowdens_set)\n",
    "        cur_comb_set = lowdens_set[:ii+1]    \n",
    "        cur_covariance = orig_covariance.clone()\n",
    "        add_features_to_covariance(le_ace, cur_comb_set, cur_covariance)\n",
    "        inv_covariance = torch.linalg.inv(cur_covariance)\n",
    "        cur_PR = 1 / torch.einsum(\"ij, jk, ik -> i\", target_features, inv_covariance, target_features)\n",
    "        cur_PRs.append(cur_PR.detach().cpu().numpy().mean())\n",
    "            \n",
    "        accuracy_dict = le_ace.train(\n",
    "            train_structures=training_set + cur_comb_set,\n",
    "            validation_structures=training_set,\n",
    "            test_structures=test_set,\n",
    "            do_gradients=False,\n",
    "            batch_size=10,\n",
    "        )\n",
    "\n",
    "        cur_RMSEs.append(accuracy_dict['test RMSE energies'])\n",
    "\n",
    "    all_RMSEs.append(np.array(cur_RMSEs))\n",
    "    all_PRs.append(np.array(cur_PRs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"lowdens_random_RSEs.npy\", np.array(all_RMSEs))\n",
    "np.save(\"lowdens_random_PRs.npy\", np.array(all_PRs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
